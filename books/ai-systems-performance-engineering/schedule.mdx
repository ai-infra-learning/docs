---
title: "阅读计划"
icon: "calendar"
---

## 时间表

| 周次 | 日期 | 章节 | 状态 |
|------|------|------|------|
| - | - | 前言 | 未开始 |
| 第 1 周 | TBD | 第一章：介绍与 AI 系统概览 | 未开始 |
| 第 2 周 | TBD | 第二章：AI 系统硬件概览 | 未开始 |
| 第 3 周 | TBD | 第三章：GPU 环境下的 OS、Docker 与 Kubernetes 调优 | 未开始 |
| 第 4 周 | TBD | 第四章：分布式网络通信调优 | 未开始 |
| 第 5 周 | TBD | 第五章：基于 GPU 的存储 I/O 优化 | 未开始 |
| 第 6 周 | TBD | 第六章：GPU 架构、CUDA 编程与最大化占用率 | 未开始 |
| 第 7 周 | TBD | 第七章：GPU 内存访问模式的分析与调优 | 未开始 |
| 第 8 周 | TBD | 第八章：占用率调优、Warp 效率与指令级并行 | 未开始 |
| 第 9 周 | TBD | 第九章：提升 CUDA Kernel 效率与算术强度 | 未开始 |
| 第 10 周 | TBD | 第十章：Kernel 内流水线、Warp 特化与协作线程块集群 | 未开始 |
| 第 11 周 | TBD | 第十一章：Kernel 间流水线、同步与 CUDA 流有序内存分配 | 未开始 |
| 第 12 周 | TBD | 第十二章：动态调度、CUDA Graphs 与设备发起的 Kernel 编排 | 未开始 |
| 第 13 周 | TBD | 第十三章：PyTorch 的分析、调优与扩展 | 未开始 |
| 第 14 周 | TBD | 第十四章：PyTorch 编译器、OpenAI Triton 与 XLA 后端 | 未开始 |
| 第 15 周 | TBD | 第十五章：多节点推理、并行、解码与路由优化 | 未开始 |
| 第 16 周 | TBD | 第十六章：大规模推理的分析、调试与调优 | 未开始 |
| 第 17 周 | TBD | 第十七章：推理中分离式 Prefill 与 Decode 的扩展 | 未开始 |
| 第 18 周 | TBD | 第十八章：高级 Prefill-Decode 与 KV Cache 调优 | 未开始 |
| 第 19 周 | TBD | 第十九章：动态与自适应推理引擎优化 | 未开始 |
| 第 20 周 | TBD | 第二十章：AI 辅助性能优化与百万级 GPU 集群扩展 | 未开始 |

<Note>
  时间表将根据实际阅读节奏持续更新。
</Note>

## 阅读建议

- 每章 2 周阅读时间，期间可以在 GitHub Issue 上交流问题
- 每章安排一次线上分享：一人带读约 40 分钟 + 20 分钟自由讨论
- 阅读后在对应章节页面记录笔记和心得
